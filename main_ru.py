import os
from openai import OpenAI

MANUS_PROXY_URL = "https://api.manus.im/api/llm-proxy/v1/"

API_KEY = os.getenv("MANUS_API_KEY")

# –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø—Ä–æ–∫—Å–∏ –º–æ–∂–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏)
MODEL_TO_USE = "gemini-2.5-flash"
# MODEL_TO_USE = "gpt-4.1-nano"
# MODEL_TO_USE = "gpt-4.1-mini"


def chat_with_manus_proxy(prompt: str):
    if not API_KEY:
        print("‚ùå –û—à–∏–±–∫–∞: API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è MANUS_API_KEY –∏–ª–∏ –≤–ø–∏—à–∏—Ç–µ –∫–ª—é—á –≤ —Å–∫—Ä–∏–ø—Ç.")
        return

    print(f"üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏: {MANUS_PROXY_URL}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {MODEL_TO_USE}")
    print(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∫–ª—é—á: {API_KEY[:10]}...{API_KEY[-4:]}")

    try:
        client = OpenAI(
            base_url=MANUS_PROXY_URL,
            api_key=API_KEY
        )

        response = client.chat.completions.create(
            model=MODEL_TO_USE,
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ]
        )

        ai_response = response.choices[0].message.content
        print("\nüí¨ –û—Ç–≤–µ—Ç –æ—Ç AI:")
        print("-" * 20)
        print(ai_response)
        print("-" * 20)
        print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens}")

    except Exception as e:
        print(f"\nüí• –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    user_prompt = "Who r u?"
    chat_with_manus_proxy(user_prompt)
